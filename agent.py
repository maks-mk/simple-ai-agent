import os
import json
import warnings
import asyncio
from pathlib import Path
from typing import List, Any, Dict, Optional, Literal
from dataclasses import dataclass, field
from functools import lru_cache
from datetime import datetime

# Third-party imports
from dotenv import load_dotenv
from langchain_core.language_models import BaseChatModel
from langchain_core.tools import tool, BaseTool
from langgraph.prebuilt import create_react_agent
from langgraph.checkpoint.memory import MemorySaver

# LLM Providers
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_openai import ChatOpenAI

# MCP
try:
    from langchain_mcp_adapters.client import MultiServerMCPClient
except ImportError:
    MultiServerMCPClient = None

# Local imports
from logging_config import setup_logging

# –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ª–æ–∫–∞–ª—å–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
try:
    from delete_tools import SafeDeleteFileTool, SafeDeleteDirectoryTool
except ImportError:
    SafeDeleteFileTool = None
    SafeDeleteDirectoryTool = None

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è
warnings.filterwarnings("ignore", category=DeprecationWarning)
warnings.filterwarnings("ignore", message=".*create_react_agent has been moved.*")
logger = setup_logging()

# === –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ===

@dataclass
class AgentConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞ —Å –∑–∞–≥—Ä—É–∑–∫–æ–π –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è."""
    provider: Literal["gemini", "openai"] = field(default="gemini")
    
    # API Keys & Models
    gemini_key: Optional[str] = field(default=None)
    gemini_model: str = field(default=None)
    openai_key: Optional[str] = field(default=None)
    openai_model: str = field(default=None)
    openai_base_url: Optional[str] = field(default=None)
    
    # Parameters
    temperature: float = 0.5
    max_retries: int = 3
    retry_delay: int = 2
    
    # Paths
    mcp_config_path: Path = Path("mcp.json")
    prompt_path: Path = Path("prompt.txt")
    memory_db_path: str = "./memory_db"
    
    # Flags
    use_long_term_memory: bool = False
    session_size: int = 6

    @classmethod
    def from_env(cls) -> 'AgentConfig':
        """–§–∞–±—Ä–∏—á–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥–∞ –∏–∑ .env"""
        load_dotenv()
        return cls(
            provider=os.getenv("PROVIDER", "gemini").lower(),
            gemini_key=os.getenv("GEMINI_API_KEY"),
            gemini_model=os.getenv("GEMINI_MODEL"),
            openai_key=os.getenv("OPENAI_API_KEY"),
            openai_model=os.getenv("OPENAI_MODEL"),
            openai_base_url=os.getenv("OPENAI_BASE_URL"),
            temperature=float(os.getenv("LLM_TEMPERATURE", "0.5")),
            max_retries=int(os.getenv("MAX_RETRIES", "3")),
            retry_delay=int(os.getenv("RETRY_DELAY", "2")),
            use_long_term_memory=os.getenv("LONG_TERM_MEMORY", "false").lower() == "true",
            session_size=int(os.getenv("SESSION_SIZE", "6")),
        )

# === –†–ê–ë–û–¢–ê –° –ü–†–û–ú–ü–¢–ê–ú–ò ===

@lru_cache(maxsize=1)
def _read_prompt_template(path: Path) -> str:
    """–ß–∏—Ç–∞–µ—Ç —à–∞–±–ª–æ–Ω –ø—Ä–æ–º–ø—Ç–∞ —Å –¥–∏—Å–∫–∞ (–∫—ç—à–∏—Ä—É–µ—Ç—Å—è)."""
    base_dir = Path(__file__).parent
    full_path = base_dir / path
    
    if full_path.exists():
        try:
            return full_path.read_text(encoding='utf-8')
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –ø—Ä–æ–º–ø—Ç–∞ {full_path}: {e}")
    
    return "–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç."

def get_system_prompt(config: AgentConfig) -> str:
    """–§–æ—Ä–º–∏—Ä—É–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏."""
    content = _read_prompt_template(config.prompt_path)
    
    now = datetime.now()
    replacements = {
        "{{current_date}}": now.strftime("%Y-%m-%d (%A)"),
        "{{current_time}}": now.strftime("%H:%M")
    }

    for key, value in replacements.items():
        if key in content:
            content = content.replace(key, value)
    
    # –ï—Å–ª–∏ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤ –Ω–µ –±—ã–ª–æ, –¥–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ –≤ –∫–æ–Ω–µ—Ü
    if "{{current_date}}" not in _read_prompt_template(config.prompt_path):
        content += f"\n\n[System Info]\nDate: {replacements['{{current_date}}']}\nTime: {replacements['{{current_time}}']}"
    
    return f"{content}\n\nCWD: {Path.cwd()}"

def load_mcp_config(config_path: Path) -> Dict[str, Any]:
    """–ß–∏—Ç–∞–µ—Ç –∏ –≤–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∫–æ–Ω—Ñ–∏–≥ MCP."""
    base_dir = Path(__file__).parent
    path = base_dir / config_path
    
    if not path.exists():
        return {}
    
    try:
        data = json.loads(path.read_text(encoding="utf-8"))
        current_dir = str(Path.cwd())
        
        filtered = {}
        for name, cfg in data.items():
            if not cfg.get("enabled", True):
                continue
            
            clean_cfg = cfg.copy()
            clean_cfg.pop("enabled", None)
            
            # –ü–æ–¥—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—É—Ç–∏ –∫ —Ç–µ–∫—É—â–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            if "args" in clean_cfg:
                clean_cfg["args"] = [
                    arg.replace("{filesystem_path}", current_dir) 
                    for arg in clean_cfg["args"]
                ]
            filtered[name] = clean_cfg
        return filtered
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ MCP –∫–æ–Ω—Ñ–∏–≥–∞: {e}")
        return {}

# === –ò–ù–°–¢–†–£–ú–ï–ù–¢–´ –ü–ê–ú–Ø–¢–ò ===

class MemoryToolsFactory:
    """–§–∞–±—Ä–∏–∫–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –ø–∞–º—è—Ç–∏ —Å –∑–∞–º—ã–∫–∞–Ω–∏–µ–º –Ω–∞ —ç–∫–∑–µ–º–ø–ª—è—Ä –ë–î."""
    
    @staticmethod
    def create(db_path: str, session_size: int) -> List[BaseTool]:
        try:
            from memory_manager import MemoryManager
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –ø–∞–º—è—Ç–∏
            memory = MemoryManager(db_path=db_path, session_size=session_size)
            logger.info(f"üß† Long-term memory loaded from {db_path}")

            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
            @tool
            def remember_fact(text: str, category: str = "general") -> str:
                """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤–∞–∂–Ω—ã–π —Ñ–∞–∫—Ç –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ –∏–ª–∏ –ø—Ä–æ–µ–∫—Ç–µ –≤ –¥–æ–ª–≥–æ–≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–º—è—Ç—å."""
                try:
                    memory.remember(text, metadata={"type": category})
                    return f"‚úÖ –ó–∞–ø–æ–º–Ω–∏–ª: {text}"
                except Exception as e:
                    return f"Error saving to memory: {e}"

            @tool
            def recall_facts(query: str) -> str:
                """–ò—â–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –¥–æ–ª–≥–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–π –ø–∞–º—è—Ç–∏."""
                try:
                    facts = memory.recall(query)
                    if not facts:
                        return "–ù–∏—á–µ–≥–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –≤ –ø–∞–º—è—Ç–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ."
                    return "–ù–∞–π–¥–µ–Ω–æ –≤ –ø–∞–º—è—Ç–∏:\n" + "\n".join(f"- {f}" for f in facts)
                except Exception as e:
                    return f"Error recalling memory: {e}"

            @tool
            def delete_facts(query: str) -> str:
                """–£–¥–∞–ª—è–µ—Ç –Ω–µ–∞–∫—Ç—É–∞–ª—å–Ω—ã–π —Ñ–∞–∫—Ç –∏–∑ –ø–∞–º—è—Ç–∏ –ø–æ –ø–æ–∏—Å–∫–æ–≤–æ–º—É –∑–∞–ø—Ä–æ—Å—É."""
                try:
                    count = memory.delete_fact_by_query(query)
                    if count > 0:
                        return f"‚úÖ –£–¥–∞–ª–µ–Ω–æ {count} —Ñ–∞–∫—Ç–æ–≤ –ø–æ –∑–∞–ø—Ä–æ—Å—É: '{query}'."
                    return f"–§–∞–∫—Ç—ã –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –ø–æ –∑–∞–ø—Ä–æ—Å—É '{query}' –Ω–µ –Ω–∞–π–¥–µ–Ω—ã."
                except Exception as e:
                    return f"Error deleting memory: {e}"

            return [remember_fact, recall_facts, delete_facts]

        except ImportError:
            logger.warning("‚ö†Ô∏è –ú–æ–¥—É–ª—å memory_manager –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü–∞–º—è—Ç—å –æ—Ç–∫–ª—é—á–µ–Ω–∞.")
            return []
        except Exception as e:
            logger.error(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–∞–º—è—Ç–∏: {e}")
            return []

# === –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ò–ù–°–¢–†–£–ú–ï–ù–¢–û–í ===

async def init_tools(config: AgentConfig) -> List[BaseTool]:
    """–°–±–æ—Ä –≤—Å–µ—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ (MCP, –ª–æ–∫–∞–ª—å–Ω—ã–µ, –ø–∞–º—è—Ç—å)."""
    all_tools = []
    
    # 1. MCP Tools
    if MultiServerMCPClient:
        mcp_cfg = load_mcp_config(config.mcp_config_path)
        if mcp_cfg:
            try:
                async with asyncio.timeout(10):
                    client = MultiServerMCPClient(mcp_cfg)
                    mcp_tools = await client.get_tools()
                    all_tools.extend(mcp_tools)
                    logger.info(f"MCP Tools initialized: {len(mcp_tools)}")
            except Exception as e:
                logger.error(f"MCP Init Failed: {e}")
    else:
        logger.warning("MCP client library not installed.")

    # 2. Local File Tools
    if SafeDeleteFileTool and SafeDeleteDirectoryTool:
        try:
            work_dir = Path.cwd()
            local_tools = [
                SafeDeleteFileTool(root_dir=work_dir),
                SafeDeleteDirectoryTool(root_dir=work_dir)
            ]
            all_tools.extend(local_tools)
            logger.info(f"Local Tools initialized: {len(local_tools)}")
        except Exception as e:
            logger.error(f"Local Tools Init Failed: {e}")

    # 3. Memory Tools
    if config.use_long_term_memory:
        mem_tools = MemoryToolsFactory.create(config.memory_db_path, config.session_size)
        all_tools.extend(mem_tools)
    
    # –í–∫–ª—é—á–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫ –¥–ª—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
    for t in all_tools:
        t.handle_tool_error = True
        
    return all_tools

# === –°–û–ó–î–ê–ù–ò–ï LLM ===

def create_llm(config: AgentConfig) -> BaseChatModel:
    """–°–æ–∑–¥–∞–µ—Ç —ç–∫–∑–µ–º–ø–ª—è—Ä LLM."""
    if config.provider == "gemini":
        if not config.gemini_key:
            raise ValueError("GEMINI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω")
        return ChatGoogleGenerativeAI(
            model=config.gemini_model,
            temperature=config.temperature,
            google_api_key=config.gemini_key,
            max_retries=config.max_retries,
            transport="rest",
        )
    elif config.provider == "openai":
        if not config.openai_key:
            raise ValueError("OPENAI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω")
        return ChatOpenAI(
            model=config.openai_model,
            temperature=config.temperature,
            api_key=config.openai_key,
            base_url=config.openai_base_url,
            max_retries=config.max_retries,
        )
    else:
        raise ValueError(f"Unknown provider: {config.provider}")

# === –°–ë–û–†–ö–ê –ì–†–ê–§–ê ===

async def create_agent_graph(config: Optional[AgentConfig] = None):
    """
    –°–æ–∑–¥–∞–µ—Ç –≥–æ—Ç–æ–≤—ã–π –∫ –∑–∞–ø—É—Å–∫—É –≥—Ä–∞—Ñ –∞–≥–µ–Ω—Ç–∞.
    """
    if config is None:
        config = AgentConfig.from_env()

    # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è/–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤
    tools = await init_tools(config)
    llm = create_llm(config)
    
    # –ü—Ä–∏–≤—è–∑–∫–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–æ–≤—Ç–æ—Ä–æ–≤
    if tools:
        llm_with_tools = llm.bind_tools(tools)
    else:
        llm_with_tools = llm # –ê–≥–µ–Ω—Ç –±–µ–∑ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
        
    llm_robust = llm_with_tools.with_retry(
        stop_after_attempt=config.max_retries,
        wait_exponential_jitter=True
    )

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
    system_prompt = get_system_prompt(config)

    # –°–æ–∑–¥–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞
    # FIX: –ò—Å–ø–æ–ª—å–∑—É–µ–º messages_modifier –≤–º–µ—Å—Ç–æ state_modifier –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    try:
        agent = create_react_agent(
            model=llm_robust,
            tools=tools,
            messages_modifier=system_prompt, 
            checkpointer=MemorySaver()
        )
    except TypeError:
        # Fallback –¥–ª—è –æ—á–µ–Ω—å —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏–π, –≥–¥–µ –∞—Ä–≥—É–º–µ–Ω—Ç –Ω–∞–∑—ã–≤–∞–ª—Å—è prompt
        agent = create_react_agent(
            model=llm_robust,
            tools=tools,
            prompt=system_prompt,
            checkpointer=MemorySaver()
        )
    
    return agent