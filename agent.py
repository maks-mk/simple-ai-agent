import json
import asyncio
import logging
import re
from pathlib import Path
from datetime import datetime
from typing import List, Optional, Literal
from pydantic import BaseModel, Field 

# --- LANGCHAIN & LANGGRAPH ---
from langchain_core.language_models import BaseChatModel
from langchain_core.tools import BaseTool
from langchain_core.messages import (
    BaseMessage, SystemMessage, RemoveMessage, HumanMessage, AIMessage, ToolMessage
)
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import MemorySaver

# --- CORE MODULES ---
from core.config import AgentConfig
from core.state import AgentState
from core.utils import AgentUtils
from tools.tool_registry import ToolRegistry
from core.tool_validator import validate_tool_execution 

# --- OPTIONAL CORE MODULES ---
from dotenv import load_dotenv

try:
    from core.tool_sanitizer import ToolSanitizer
except ImportError:
    class ToolSanitizer:
        @staticmethod
        def sanitize_tool_calls(tc): pass
        
try:
    from core.safety_guard import SafetyGuard
except ImportError:
    class SafetyGuard:
        ENABLED = False
        @classmethod
        def is_unsafe_write(cls, *args): return False

try:
    from core.logging_config import setup_logging
    logger = setup_logging() 
except ImportError:
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger("agent")

# ==========================================
# –ì–†–ê–§ –ê–ì–ï–ù–¢–ê (WORKFLOW)
# ==========================================

class IntentClassification(BaseModel):
    intent: Literal["read_only", "write_action"] = Field(
        description="User's intent: 'read_only' (search, query, view) or 'write_action' (create, edit, delete, patch, fix, modify)."
    )
    reasoning: str = Field(description="Short explanation of why this intent was chosen.")

class AgentWorkflow:
    def __init__(self):
        load_dotenv()
        self.config = AgentConfig()
        self.utils = AgentUtils()
        self.tool_registry = ToolRegistry(self.config)
        
        self.llm: Optional[BaseChatModel] = None
        self.llm_with_tools: Optional[BaseChatModel] = None
        
        # –ö—ç—à –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
        self.tool_buckets = {}

    async def initialize_resources(self):
        logger.info(f"Initializing agent: [bold cyan]{self.config.provider}[/]", extra={"markup": True})
        
        self.llm = self.config.get_llm()
        await self.tool_registry.load_all()
        
        # 1. –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã (Safe vs Write)
        self.tool_buckets = self._classify_tools()
        logger.info(f"üß† Tool Capabilities: {len(self.tool_buckets['safe'])} safe, {len(self.tool_buckets['write'])} write.")
        
        can_use_tools = self.config.check_tool_support()
        
        if self.tool_registry.tools and can_use_tools:
            try:
                self.llm_with_tools = self.llm.bind_tools(self.tool_registry.tools)
                logger.info("üõ†Ô∏è Tools bound to LLM successfully.")
            except Exception as e:
                logger.error(f"Failed to bind tools: {e}")
                self.llm_with_tools = self.llm
        else:
            if not can_use_tools:
                logger.debug("‚ö†Ô∏è Tools disabled: Model does not support tool calling.")
            self.llm_with_tools = self.llm

    def _classify_tools(self):
        """
        –î–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç ToolRegistry –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π.
        """
        buckets = {
            "safe": [],
            "write": []
        }
        
        for t in self.tools:
            capability = self.tool_registry.get_tool_capability(t)
            
            if capability == "write":
                buckets["write"].append(t.name)
            else:
                buckets["safe"].append(t.name)
                
        return buckets

    @property
    def tools(self) -> List[BaseTool]:
        return self.tool_registry.tools

    # --- NODES ---

    async def _summarize_node(self, state: AgentState):
        messages = state["messages"]
        summary = state.get("summary", "")

        if len(messages) <= self.config.summary_threshold:
            return {}

        idx = len(messages) - self.config.summary_keep_last
        if idx < 0: idx = 0

        # –ü–æ–ø—ã—Ç–∫–∞ –Ω–∞–π—Ç–∏ HumanMessage –≤ —Ö–≤–æ—Å—Ç–µ, —á—Ç–æ–±—ã —Å–¥–µ–ª–∞—Ç—å –∫—Ä–∞—Å–∏–≤—ã–π —Ä–∞–∑—Ä–µ–∑
        scan_idx = idx
        found_human = False
        while scan_idx < len(messages):
            if isinstance(messages[scan_idx], HumanMessage):
                idx = scan_idx
                found_human = True
                break
            scan_idx += 1
        
        # –ï—Å–ª–∏ HumanMessage –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ö–≤–æ—Å—Ç–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∂–µ—Å—Ç–∫–∏–π idx (keep_last)
        
        to_summarize = messages[:idx]
        if not to_summarize: return {}

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –∏—Å—Ç–æ—Ä–∏–∏ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –¥–ª–∏–Ω—ã –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤
        history_parts = []
        for m in to_summarize:
            content = str(m.content)
            if len(content) > 500:
                content = content[:500] + "... [truncated]"
            history_parts.append(f"{m.type}: {content}")
        
        history_text = "\n".join(history_parts)
        
        prompt = (
            f"Current memory context:\n<previous_context>\n{summary}\n</previous_context>\n\n"
            f"New events:\n{history_text}\n\n"
            "Update <previous_context>. Keep only key facts, decisions, and results. "
            "Remove chit-chat. Return only the updated context text."
        )
        
        try:
            res = await self.llm.ainvoke(prompt)
            delete_msgs = [RemoveMessage(id=m.id) for m in to_summarize if m.id]
            logger.info(f"üßπ Summary: Removed {len(delete_msgs)} messages.")
            return {"summary": res.content, "messages": delete_msgs}
        except Exception as e:
            logger.error(f"Summarization Error: {e}")
            return {}

    async def _tool_filter_node(self, state: AgentState):
        """
        Smart Tool Filtering (v6.2).
        Combines deterministic checks (Recovery, Active Tool) with LLM-based Intent Classification.
        """
        # 0. Global Bypass via Config
        if not self.config.enable_tool_filtering:
            logger.debug("üîì Filter: DISABLED by config (All tools allowed)")
            return {"allowed_tools": None}

        messages = state["messages"]
        phase = "exploration"
        last_msg = messages[-1] if messages else None

        # 1. RECOVERY PHASE (Priority #1)
        if isinstance(last_msg, SystemMessage):
            text = str(last_msg.content).upper()
            if "SYSTEM ALERT" in text or "DO NOT RETRY" in text:
                phase = "recovery"
                logger.debug("üõ° Filter: RECOVERY phase (System alert detected)")
                return {"allowed_tools": self.tool_buckets["safe"]}

        # 2. ACTION PHASE (Priority #2)
        # –ï—Å–ª–∏ –º—ã —É–∂–µ –≤ —Ü–∏–∫–ª–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ (–ø—Ä–µ–¥—ã–¥—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ - ToolMessage),
        # –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–∑—Ä–µ—à–∞—Ç—å –¥–æ—Å—Ç—É–ø, —á—Ç–æ–±—ã –∞–≥–µ–Ω—Ç –º–æ–≥ –∑–∞–≤–µ—Ä—à–∏—Ç—å –Ω–∞—á–∞—Ç–æ–µ.
        if phase != "recovery":
            for m in reversed(messages):
                if isinstance(m, ToolMessage):
                    content = str(m.content)
                    if content and not content.startswith("Error"):
                        phase = "action"
                        break
                if isinstance(m, HumanMessage):
                    break # Stop looking back at previous turn

        # 3. LLM INTENT CLASSIFICATION (Priority #3)
        # –ï—Å–ª–∏ —Ñ–∞–∑–∞ –≤—Å–µ –µ—â–µ "exploration" –∏ –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç —á–µ–ª–æ–≤–µ–∫–∞,
        # –∏—Å–ø–æ–ª—å–∑—É–µ–º LLM –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–∞–º–µ—Ä–µ–Ω–∏—è.
        if phase == "exploration" and isinstance(last_msg, HumanMessage):
            # Fast Path: Check for direct tool mentions first (optimization)
            text = last_msg.content.lower()
            write_tool_names = [name.lower() for name in self.tool_buckets["write"]]
            
            if any(t_name in text for t_name in write_tool_names):
                phase = "intent_action"
                logger.debug("‚ö° Filter: Fast Path (Tool mentioned) -> Write Allowed")
            else:
                # LLM Path
                try:
                    classifier = self.llm.with_structured_output(IntentClassification)
                    
                    # SYSTEM PROMPT –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
                    system_prompt = SystemMessage(content=(
                        "Analyze the conversation and determine the user's intent. "
                        "Return a JSON object with 'intent' and 'reasoning'. "
                        "If the user wants to create, edit, save, delete, or modify files/system -> 'write_action'. "
                        "If the user just wants to search, read, or ask questions -> 'read_only'."
                    ))
                    
                    # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                    context_msgs = [system_prompt] + messages[-3:]
                    
                    classification = await classifier.ainvoke(context_msgs)
                    
                    if classification.intent == "write_action":
                        phase = "intent_action"
                        logger.info(f"üß† Intent: WRITE detected. Reason: {classification.reasoning}")
                    else:
                        logger.info(f"üß† Intent: READ detected. Reason: {classification.reasoning}")
                        
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Intent Classifier Failed: {e}. Falling back to keyword search.")
                    # Fallback to keywords (Safety Net)
                    intent_hints = (
                        "—Å–æ–∑–¥–∞–π", "—Å–æ–∑–¥–∞—Ç—å", "–∑–∞–ø–∏—à–∏", "–∑–∞–ø–∏—Å–∞—Ç—å", "—Å–æ—Ö—Ä–∞–Ω–∏",
                        "—Å–¥–µ–ª–∞–π", "—Å–¥–µ–ª–∞—Ç—å", "–Ω–∞–ø–∏—à–∏", "–Ω–∞–ø–∏—Å–∞—Ç—å", "–∏–∑–º–µ–Ω–∏",
                        "–¥–æ–±–∞–≤—å", "–¥–æ–±–∞–≤–∏—Ç—å", "–æ–±–Ω–æ–≤–∏", "–æ–±–Ω–æ–≤–∏—Ç—å", "–∏—Å–ø—Ä–∞–≤—å", "–ø–æ—á–∏–Ω–∏",
                        "create", "write", "save", "generate", "edit", "update", "delete",
                        "add", "insert", "modify", "fix", "replace", "patch"
                    )
                    if any(hint in text for hint in intent_hints):
                        phase = "intent_action"

        # 4. TOOL GATING
        if phase in ["action", "intent_action"]:
            allowed = None # All tools allowed
            logger.debug(f"üîì Filter: {phase.upper()} (All tools allowed)")
        else:
            allowed = self.tool_buckets["safe"]
            logger.debug(f"üîí Filter: {phase.upper()} ({len(allowed)} safe tools allowed)")

        return {"allowed_tools": allowed}
        
    async def _tools_and_validate_node(self, state: AgentState):
        messages = state["messages"]
        last_msg = messages[-1]
        
        if not isinstance(last_msg, AIMessage) or not last_msg.tool_calls:
            return {}
            
        final_messages = []
        validation_errors = []
        should_force_retry = False
        tool_retries = state.get("tool_retries", {}).copy()

        for tool_call in last_msg.tool_calls:
            t_name = tool_call["name"]
            t_args = tool_call["args"]
            t_id = tool_call["id"]
            
            # 1. –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞
            tool = next((t for t in self.tools if t.name == t_name), None)
            content = ""
            
            if not tool:
                content = f"Error: Tool '{t_name}' not found."
            else:
                try:
                    raw_result = await tool.ainvoke(t_args)
                    content = str(raw_result)
                except Exception as e:
                    content = f"Error: {str(e)}"

            if not content.strip():
                content = "Error: Tool returned empty response."

            # –°–æ–∑–¥–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ (–ø–æ–∫–∞ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ)
            tool_msg = ToolMessage(content=content, tool_call_id=t_id, name=t_name)

            # 2. –í–∞–ª–∏–¥–∞—Ü–∏—è
            result = validate_tool_execution(tool_msg, t_args, t_name)
            
            if not result["is_valid"]:
                logger.debug(f"Tool Error ({t_name}): {result['error_message']}")
                
                # --- [FIX START] –£–º–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ—Ç—Ä–∞–µ–≤ ---
                retry_count = tool_retries.get(t_name, 0)
                
                if result["retry_needed"]:
                    if retry_count < 3:
                        # –†–∞–∑—Ä–µ—à–∞–µ–º –ø–æ–≤—Ç–æ—Ä (–º—è–≥–∫–∞—è –æ—à–∏–±–∫–∞)
                        tool_retries[t_name] = retry_count + 1
                        should_force_retry = True
                        validation_errors.append(f"- Tool '{t_name}' failed (Attempt {retry_count+1}/3): {result['error_message']}")
                    else:
                        # –õ–∏–º–∏—Ç –∏—Å—á–µ—Ä–ø–∞–Ω! –ñ–ï–°–¢–ö–ò–ô –ë–õ–û–ö.
                        # –ú—ã –ø–æ–¥–º–µ–Ω—è–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç —Å–æ–æ–±—â–µ–Ω–∏—è, —á—Ç–æ–±—ã LLM —É–≤–∏–¥–µ–ª–∞ —Ç—É–ø–∏–∫.
                        error_text = f"SYSTEM BLOCK: Too many consecutive errors for '{t_name}'. The tool is failing repeatedly with: {content[:200]}..."
                        tool_msg.content = error_text 
                        validation_errors.append(f"- STOP: {t_name} blocked due to repeated failures.")
                        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫, —Ç–∞–∫ –∫–∞–∫ –º—ã —É–∂–µ –Ω–∞–∫–∞–∑–∞–ª–∏ –∞–≥–µ–Ω—Ç–∞
                        if t_name in tool_retries: del tool_retries[t_name]
                else:
                    # –ï—Å–ª–∏ retry_needed=False (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ñ–∞–π–ª–∞ –Ω–µ—Ç), –ø—Ä–æ—Å—Ç–æ —Å–æ–æ–±—â–∞–µ–º
                    validation_errors.append(f"- Tool '{t_name}' returned: {result['error_message']}")
                
            else:
                # –£—Å–ø–µ—Ö - —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫ –¥–ª—è —ç—Ç–æ–≥–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞
                if t_name in tool_retries: del tool_retries[t_name]

            final_messages.append(tool_msg)

        # 3. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ —Å–æ–≤–µ—Ç–∞
        if validation_errors:
            if should_force_retry:
                advice = "INSTRUCTION: Arguments invalid or tool failed. Review the error and TRY AGAIN with corrected parameters."
            else:
                # –ï—Å–ª–∏ –º—ã –∑–¥–µ—Å—å, –∑–Ω–∞—á–∏—Ç –ª–∏–±–æ —Ä–µ—Ç—Ä–∞–∏ –∫–æ–Ω—á–∏–ª–∏—Å—å, –ª–∏–±–æ –æ—à–∏–±–∫–∞ —Ñ–∞—Ç–∞–ª—å–Ω–∞
                advice = (
                    "INSTRUCTION: Action failed repeatedly or is impossible. "
                    "DO NOT RETRY the same tool with the same arguments. "
                    "Stop and analyze the error. Try a different approach (e.g., check file existence first)."
                )
            
            err_text = "\n".join(validation_errors)
            final_messages.append(SystemMessage(content=f"SYSTEM ALERT:\n{err_text}\n{advice}"))

        return {
            "messages": final_messages,
            "tool_retries": tool_retries
        }
        
    async def _agent_node(self, state: AgentState):
        messages = state["messages"]
        
        # --- DYNAMIC BINDING (–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤) ---
        allowed = state.get("allowed_tools")
        if allowed is not None:
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ø–∏—Å–æ–∫
            selected_tools = [t for t in self.tools if t.name in allowed]
            current_llm = self.llm.bind_tools(selected_tools)
        else:
            # –ü–æ–ª–Ω—ã–π –¥–æ—Å—Ç—É–ø
            current_llm = self.llm_with_tools
        # -------------------------------------------------

        tools_available = (current_llm != self.llm)
        
        sys_msg = self._build_system_message(state.get("summary", ""), tools_available)
        full_context = [sys_msg] + messages
        
        response = await self._invoke_llm_with_retry(current_llm, full_context)
        
        last_tool_call = None
        
        # SafetyGuard (–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Å–ª–æ–π)
        if SafetyGuard.is_unsafe_write(response, full_context):
            response = SystemMessage(
                content="STOP. You are trying to write a file without valid data from search/fetch. "
                        "Perform a search first to get actual content."
            )
            
        elif isinstance(response, AIMessage) and response.tool_calls:
            ToolSanitizer.sanitize_tool_calls(response.tool_calls)
            last_tool_call = response.tool_calls[0]
            
            for tc in response.tool_calls:
                if tc['name'] in ['write_file', 'save_file']:
                    raw_path = str(tc['args'].get('path', '')).strip()
                    if len(raw_path) < 2 or re.match(r'^[\.,\-_:;\'" ]+$', raw_path):
                        logger.debug(f"üõ°Ô∏è Quality Gate: Rejecting garbage filename '{raw_path}'")
                        response = SystemMessage(
                            content=f"SYSTEM ERROR: The filename '{raw_path}' is invalid. "
                                    "Please RETRY with a meaningful filename."
                        )
                        last_tool_call = None
                        break 
                        
        if isinstance(response, AIMessage):
            self._patch_token_usage(response, full_context)
        
        if isinstance(response, AIMessage) and response.tool_calls:
            last_msg = messages[-1] if messages else None
            if isinstance(last_msg, ToolMessage):
                current_tool = response.tool_calls[0]['name']
                last_tool = last_msg.name
                if current_tool == "write_file" and last_tool == "write_file":
                    logger.warning("üõë Loop Guard: Blocked repetitive write_file.")
                    response = AIMessage(
                        content="System: File already written. Stop overwriting."
                    )

        return {
            "messages": [response],
            "last_tool_call": last_tool_call
        }
        
    async def _loop_guard_node(self, state: AgentState):
        return {"messages": [AIMessage(content="üõë **Auto-Stop**: Max steps limit reached.")]}

    # --- HELPERS ---

    def _build_system_message(self, summary: str, tools_available: bool = True) -> SystemMessage:
        if self.config.prompt_path.exists():
            raw_prompt = self.config.prompt_path.read_text("utf-8")
            logger.info(f"‚úÖ System prompt loaded from: {self.config.prompt_path} ({len(raw_prompt)} chars)")
        else:
            logger.warning(f"‚ö†Ô∏è System prompt not found at: {self.config.prompt_path}. Using fallback.")
            raw_prompt = (
                "You are an autonomous AI agent.\n"
                "Reason in English, Reply in Russian.\n"
                "Date: {{current_date}}\nCWD: {{cwd}}"
            )
        
        prompt = raw_prompt.replace("{{current_date}}", datetime.now().strftime("%Y-%m-%d"))
        prompt = prompt.replace("{{cwd}}", str(Path.cwd()))
        
        if not tools_available:
            prompt += "\nNOTE: You are in CHAT-ONLY mode. Tools are disabled for this session."
        elif self.config.use_long_term_memory:
             prompt += "\nUse memory tools (recall_facts/remember_fact) when necessary."
             
        if summary:
            prompt += f"\n\n<memory>\n{summary}\n</memory>"
            
        return SystemMessage(content=prompt)

    async def _invoke_llm_with_retry(self, llm, context: List[BaseMessage]) -> AIMessage:
        FATAL_ERRORS = ["401", "unauthorized", "quota", "billing", "context_length_exceeded"]

        for attempt in range(3):
            try:
                response = await llm.ainvoke(context)
                if not response.content and not response.tool_calls:
                    raise ValueError("Empty response from LLM")
                return response

            except Exception as e:
                error_str = str(e).lower()
                if any(err in error_str for err in FATAL_ERRORS):
                    logger.error(f"üõë Fatal LLM Error: {e}")
                    return AIMessage(content=f"System Error: API refused request ({e})")

                if attempt < 2:
                    logger.debug(f"‚ö†Ô∏è LLM Crash (Attempt {attempt+1}): {e}. Retrying...")
                    await asyncio.sleep(1)
                    continue
                
                logger.error(f"üíÄ All retries failed: {e}")
            
        return AIMessage(content=f"**System Failure**: Multiple API crashes.")
      
    def _patch_token_usage(self, response: AIMessage, context: List[BaseMessage]):
        usage = response.usage_metadata or {}
        if (isinstance(usage, dict) and usage.get("input_tokens", 0) > 0):
            return

        meta = response.response_metadata or {}
        add_kwargs = response.additional_kwargs or {}

        candidates = [
            meta.get("usage"),
            meta.get("token_usage"),
            add_kwargs.get("usage"),
            add_kwargs.get("token_usage"),
            meta.get("body", {}).get("usage") if isinstance(meta.get("body"), dict) else None,
        ]

        raw_usage = None
        for c in candidates:
            if isinstance(c, dict) and ("prompt_tokens" in c or "completion_tokens" in c):
                raw_usage = c
                break

        if raw_usage:
            input_tokens = raw_usage.get("prompt_tokens", 0)
            output_tokens = raw_usage.get("completion_tokens", 0)
            total_tokens = raw_usage.get("total_tokens", input_tokens + output_tokens)

            if input_tokens > 0 or output_tokens > 0:
                response.usage_metadata = {
                    "input_tokens": input_tokens,
                    "output_tokens": output_tokens,
                    "total_tokens": total_tokens,
                    "token_source": "Provider"
                }
                return

        input_tokens = self.utils.estimate_payload_tokens(context, self.tools)
        output_content = response.content
        if isinstance(output_content, list):
            output_content = " ".join(str(x) for x in output_content)

        output_tokens = self.utils.count_tokens(str(output_content))
        if response.tool_calls:
            output_tokens += self.utils.count_tokens(json.dumps(response.tool_calls, default=str))

        response.usage_metadata = {
            "input_tokens": input_tokens,
            "output_tokens": output_tokens,
            "total_tokens": input_tokens + output_tokens,
            "token_source": "Manual"
        }
    
    # --- GRAPH BUILDER ---

    def build_graph(self):
        workflow = StateGraph(AgentState)

        workflow.add_node("summarize", self._summarize_node)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞—à –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä
        workflow.add_node("tool_filter", self._tool_filter_node)
        
        workflow.add_node("agent", self._agent_node)
        workflow.add_node("loop_guard", self._loop_guard_node)
        workflow.add_node("update_step", lambda state: {"steps": state.get("steps", 0) + 1})
        workflow.add_node("tools", self._tools_and_validate_node)
        
        tools_enabled = bool(self.tools) and self.config.check_tool_support()

        workflow.add_edge(START, "summarize")
        workflow.add_edge("summarize", "update_step")
        
        # –ñ–µ—Å—Ç–∫–∏–π –º–∞—Ä—à—Ä—É—Ç: update -> filter -> agent
        workflow.add_edge("update_step", "tool_filter")
        workflow.add_edge("tool_filter", "agent")

        def should_continue(state: AgentState):
            steps = state.get("steps", 0)
            messages = state.get("messages", [])

            if steps >= self.config.max_loops:
                logger.debug(f"üõë Loop Guard: {steps} steps.")
                return "loop_guard"

            if not messages: return "agent"
            last_msg = messages[-1]

            if isinstance(last_msg, SystemMessage): return "agent"
            if tools_enabled and isinstance(last_msg, AIMessage) and last_msg.tool_calls:
                return "tools"
            if isinstance(last_msg, ToolMessage): return "agent"
            return END

        destinations = ["tools", "loop_guard", "agent", END] if tools_enabled else ["loop_guard", END]
        workflow.add_conditional_edges("agent", should_continue, destinations)

        if tools_enabled:
            # –ü–æ—Å–ª–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –≤ —Ñ–∏–ª—å—Ç—Ä, 
            # —á—Ç–æ–±—ã –æ–Ω —É–≤–∏–¥–µ–ª —É—Å–ø–µ—à–Ω—ã–π ToolMessage –∏ –æ—Ç–∫—Ä—ã–ª –¥–æ—Å—Ç—É–ø –∫ write
            workflow.add_edge("tools", "tool_filter")

        workflow.add_edge("loop_guard", END)

        return workflow.compile(checkpointer=MemorySaver())

if __name__ == "__main__":
    async def main():
        wf = AgentWorkflow()
        await wf.initialize_resources()
        print(f"‚úÖ Agent Ready. Tools: {len(wf.tools)}")

    asyncio.run(main())
