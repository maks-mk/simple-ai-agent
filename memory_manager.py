"""
memory_manager.py

ÐœÐ¾Ð´ÑƒÐ»ÑŒ Ð´Ð»Ñ Ð´Ð¾Ð»Ð³Ð¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾Ð¹ Ð¿Ð°Ð¼ÑÑ‚Ð¸ AI-Ð°Ð³ÐµÐ½Ñ‚Ð° Ñ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼ ChromaDB.
ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½: deque Ð´Ð»Ñ ÑÐµÑÑÐ¸Ð¸, Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¾Ð², Singleton Ð´Ð»Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸.
"""

import logging
import hashlib
import functools
from typing import List, Dict, Optional, Any
from collections import deque

try:
    import chromadb
    from sentence_transformers import SentenceTransformer
except ImportError:
    chromadb = None  # type: ignore
    SentenceTransformer = None  # type: ignore

logger = logging.getLogger(__name__)

class MemoryManager:
    _model_instance = None  # Singleton Ð´Ð»Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸ ÐºÐ»Ð°ÑÑÐ°

    def __init__(
        self,
        db_path: str = "./memory_db",
        embedding_model: str = "paraphrase-multilingual-MiniLM-L12-v2",
        top_k: int = 5,
        session_size: int = 6
    ):
        if chromadb is None or SentenceTransformer is None:
            raise ImportError("ÐÐµ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ñ‹ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸: pip install chromadb sentence-transformers")

        self.db_path = db_path
        self.embedding_model_name = embedding_model
        self.top_k = top_k
        
        # ÐžÐŸÐ¢Ð˜ÐœÐ˜Ð—ÐÐ¦Ð˜Ð¯: deque Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ ÑƒÐ´Ð°Ð»ÑÐµÑ‚ ÑÑ‚Ð°Ñ€Ñ‹Ðµ ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ñ‹ Ð¿Ñ€Ð¸ Ð¿ÐµÑ€ÐµÐ¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ð¸
        self.session_history: deque = deque(maxlen=session_size)

        # 1. Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ ChromaDB
        try:
            # settings=chromadb.Settings(anonymized_telemetry=False) Ð¼Ð¾Ð¶Ð½Ð¾ Ð´Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð´Ð»Ñ Ð¾Ñ‚ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ Ñ‚ÐµÐ»ÐµÐ¼ÐµÑ‚Ñ€Ð¸Ð¸
            self.client = chromadb.PersistentClient(path=db_path)
            self.collection = self.client.get_or_create_collection(name="memory")
            logger.info(f"ðŸ“‚ ÐŸÐ°Ð¼ÑÑ‚ÑŒ Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð°: {db_path}")
        except Exception as e:
            logger.critical(f"âŒ ÐšÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ° ChromaDB: {e}")
            raise e

        # 2. Ð›ÐµÐ½Ð¸Ð²Ð°Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»Ð¸
        self._load_model()

    def _load_model(self):
        """Singleton Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ñ‚ÑÐ¶ÐµÐ»Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼ÐµÑ€Ð¾Ð²."""
        if MemoryManager._model_instance is None:
            logger.info(f"â³ Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»Ð¸ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¾Ð²: {self.embedding_model_name}...")
            # ÐžÐŸÐ¢Ð˜ÐœÐ˜Ð—ÐÐ¦Ð˜Ð¯: device='cpu' ÑÐ²Ð½Ð¾, ÐµÑÐ»Ð¸ Ð½ÑƒÐ¶Ð½Ð¾, Ð¸Ð»Ð¸ auto
            MemoryManager._model_instance = SentenceTransformer(self.embedding_model_name)
            logger.info("âœ… ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð°.")
        self.model = MemoryManager._model_instance

    @staticmethod
    @functools.lru_cache(maxsize=128)
    def _generate_id(text: str) -> str:
        """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ ID (SHA256). ÐšÑÑˆÐ¸Ñ€ÑƒÐµÑ‚ÑÑ Ð´Ð»Ñ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€ÑÑŽÑ‰Ð¸Ñ…ÑÑ ÑÑ‚Ñ€Ð¾Ðº."""
        return hashlib.sha256(text.strip().encode("utf-8")).hexdigest()

    def _get_embedding(self, text: str) -> List[float]:
        """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³."""
        # ÐžÐŸÐ¢Ð˜ÐœÐ˜Ð—ÐÐ¦Ð˜Ð¯: normalize_embeddings=True ÑƒÐ»ÑƒÑ‡ÑˆÐ°ÐµÑ‚ Ð¿Ð¾Ð¸ÑÐº Ñ‡ÐµÑ€ÐµÐ· cosine similarity
        return self.model.encode([text], show_progress_bar=False, normalize_embeddings=True)[0].tolist()

    # ------------------ Ð”Ð¾Ð»Ð³Ð¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð°Ñ Ð¿Ð°Ð¼ÑÑ‚ÑŒ ------------------

    def remember(self, text: str, metadata: Optional[Dict[str, Any]] = None) -> bool:
        """Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ Ñ„Ð°ÐºÑ‚ (Upsert)."""
        if not text or not text.strip():
            return False

        text = text.strip()
        doc_id = self._generate_id(text)
        
        try:
            emb = self._get_embedding(text)
            self.collection.upsert(
                ids=[doc_id],
                documents=[text],
                embeddings=[emb],
                metadatas=[metadata or {"source": "user", "type": "general"}]
            )
            logger.info(f"ðŸ’¾ Ð—Ð°Ð¿Ð¾Ð¼Ð½Ð¸Ð»: {text[:50]}...")
            return True
        except Exception as e:
            logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ: {e}")
            return False

    def recall(self, query: str, n_results: int = None) -> List[str]:
        """ÐŸÐ¾Ð¸ÑÐº Ð¿Ð¾Ñ…Ð¾Ð¶Ð¸Ñ… Ñ„Ð°ÐºÑ‚Ð¾Ð²."""
        if not query.strip() or self.collection.count() == 0:
            return []

        limit = n_results or self.top_k
        try:
            emb = self._get_embedding(query)
            results = self.collection.query(
                query_embeddings=[emb],
                n_results=limit
            )
            # results['documents'] ÑÑ‚Ð¾ [[doc1, doc2, ...]]
            return results.get("documents", [[]])[0]
        except Exception as e:
            logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð¸ÑÐºÐ°: {e}")
            return []

    def delete_fact_by_query(self, query: str, n_results: int = 1) -> int:
        """ÐÐ°Ñ…Ð¾Ð´Ð¸Ñ‚ Ñ„Ð°ÐºÑ‚ Ð¿Ð¾ ÑÐ¼Ñ‹ÑÐ»Ñƒ Ð¸ ÑƒÐ´Ð°Ð»ÑÐµÑ‚ ÐµÐ³Ð¾."""
        if not query.strip() or self.collection.count() == 0:
            return 0
            
        try:
            # 1. ÐÐ°Ñ…Ð¾Ð´Ð¸Ð¼ ÐºÐ°Ð½Ð´Ð¸Ð´Ð°Ñ‚Ð¾Ð²
            candidates = self.recall(query, n_results=n_results)
            if not candidates:
                return 0

            # 2. Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÐ¼ Ð¸Ñ… ID
            ids_to_delete = [self._generate_id(text) for text in candidates]
            
            # 3. Ð£Ð´Ð°Ð»ÑÐµÐ¼
            self.collection.delete(ids=ids_to_delete)
            logger.warning(f"ðŸ—‘ï¸ Ð£Ð´Ð°Ð»ÐµÐ½Ð¾ Ñ„Ð°ÐºÑ‚Ð¾Ð²: {len(ids_to_delete)} (Ð·Ð°Ð¿Ñ€Ð¾Ñ: '{query}')")
            return len(ids_to_delete)
            
        except Exception as e:
            logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ñ: {e}")
            return 0

    def wipe_memory(self):
        """ÐŸÐ¾Ð»Ð½Ð°Ñ Ð¾Ñ‡Ð¸ÑÑ‚ÐºÐ°."""
        try:
            self.client.delete_collection("memory")
            self.collection = self.client.get_or_create_collection("memory")
            logger.warning("ðŸ§¹ ÐŸÐ°Ð¼ÑÑ‚ÑŒ Ð¾Ñ‡Ð¸Ñ‰ÐµÐ½Ð°.")
        except Exception as e:
            logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð²Ð°Ð¹Ð¿Ð°: {e}")

    # ------------------ Ð¡ÐµÑÑÐ¸Ñ (Deque) ------------------

    def add_to_session(self, role: str, content: str):
        if content:
            self.session_history.append({"role": role, "content": content})

    def get_session_history(self) -> List[Dict[str, str]]:
        return list(self.session_history)
    
    def clear_session(self):
        self.session_history.clear()