import streamlit as st
import asyncio
import uuid
import time
from typing import Dict, Any, Optional

# === –ü–†–û–í–ï–†–ö–ê –ó–ê–í–ò–°–ò–ú–û–°–¢–ï–ô ===
try:
    import nest_asyncio
except ImportError:
    st.error("–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ nest_asyncio –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install nest_asyncio")
    st.stop()

from langchain_core.messages import HumanMessage, BaseMessage
# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∏–∑ –Ω–∞—à–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ agent.py
from agent import create_agent_graph, AgentConfig

# ----------------------------
# 1. –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –°–¢–†–ê–ù–ò–¶–´ –ò –°–¢–ò–õ–ò
# ----------------------------

# –ü–∞—Ç—á–∏–º asyncio –¥–ª—è —Ä–∞–±–æ—Ç—ã –≤–Ω—É—Ç—Ä–∏ Streamlit
nest_asyncio.apply()

st.set_page_config(page_title="Smart AI Agent", page_icon="ü§ñ", layout="wide")

st.markdown("""
<style>
    /* 1. –ì–õ–ê–í–ù–û–ï: –¢—è–Ω–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –≤–≤–µ—Ä—Ö */
    .block-container {
        padding-top: 1rem !important; /* –ë—ã–ª–æ ~6rem, —Å—Ç–∞–≤–∏–º 1.5rem */
        padding-bottom: 2rem !important;
        margin-top: 0 !important;
    }

    /* 2. –°–∂–∏–º–∞–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä —à–∞–ø–∫–∏ */
        header[data-testid="stHeader"] {
        height: 2rem !important;
        min-height: 1.5rem !important;
        padding-top: 0.25rem !important;
        padding-bottom: 0.25rem !important;
        background-color: rgba(0, 0, 0, 0.2) !important;
    }

    /* –£–º–µ–Ω—å—à–∞–µ–º –≤–µ—Ä—Ö–Ω–∏–π –æ—Ç—Å—Ç—É–ø –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ */
        .main .block-container {
            padding-top: 1rem !important;
    }
    
    /* 3. –£–±–∏—Ä–∞–µ–º —Ä–∞–¥—É–∂–Ω—É—é –ø–æ–ª–æ—Å–∫—É —Å–≤–µ—Ä—Ö—É (–æ–Ω–∞ –∑–∞–Ω–∏–º–∞–µ—Ç –º–µ—Å—Ç–æ) */
    div[data-testid="stDecoration"] {
        display: none;
    }

    /* 4. –ü–æ–¥–Ω–∏–º–∞–µ–º –∫–Ω–æ–ø–∫–∏ –º–µ–Ω—é (–≥–∞–º–±—É—Ä–≥–µ—Ä –∏ Deploy), —á—Ç–æ–±—ã –æ–Ω–∏ –≤–ª–µ–∑–ª–∏ –≤ —É–∑–∫—É—é —à–∞–ø–∫—É */
    div[data-testid="stToolbar"] {
        top: 0rem !important; /* –ü—Ä–∏–∂–∏–º–∞–µ–º –∫ —Å–∞–º–æ–º—É –≤–µ—Ä—Ö—É */
        right: 2rem !important;
        height: 2.5rem !important;
    }
    
    /* (–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –æ—Ç—Å—Ç—É–ø—ã —É –∫–Ω–æ–ø–æ–∫ –≤–Ω—É—Ç—Ä–∏ –º–µ–Ω—é */
    div[data-testid="stToolbar"] button {
        border: none;
    }
</style>
""", unsafe_allow_html=True)

# ----------------------------
# 2. –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –ö–õ–ê–°–°–´
# ----------------------------

class TokenTracker:
    """–ö–ª–∞—Å—Å –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Å—Ç—Ä–∏–º–µ."""
    def __init__(self):
        self.usage_stats: Dict[str, Dict[str, int]] = {}

    def update(self, message: BaseMessage):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏—è."""
        if not hasattr(message, "usage_metadata") or not message.usage_metadata:
            return

        msg_id = getattr(message, "id", "unknown")
        new_usage = message.usage_metadata

        if msg_id in self.usage_stats:
            current = self.usage_stats[msg_id]
            # –ë–µ—Ä–µ–º MAX, —Ç–∞–∫ –∫–∞–∫ –≤ —Å—Ç—Ä–∏–º–µ –¥–∞–Ω–Ω—ã–µ –º–æ–≥—É—Ç –ø—Ä–∏—Ö–æ–¥–∏—Ç—å –∫—É–º—É–ª—è—Ç–∏–≤–Ω–æ
            self.usage_stats[msg_id] = {
                "input_tokens": max(current.get("input_tokens", 0), new_usage.get("input_tokens", 0)),
                "output_tokens": max(current.get("output_tokens", 0), new_usage.get("output_tokens", 0)),
            }
        else:
            self.usage_stats[msg_id] = new_usage

    def get_totals(self) -> Dict[str, int]:
        total_in = sum(s.get("input_tokens", 0) for s in self.usage_stats.values())
        total_out = sum(s.get("output_tokens", 0) for s in self.usage_stats.values())
        return {"in": total_in, "out": total_out, "total": total_in + total_out}

    def get_display_html(self) -> str:
        stats = self.get_totals()
        if stats['total'] == 0:
            return ""
        return f"""
        <div class='token-badge'>
            ü™ô Tokens: <b>{stats['total']}</b> (In: {stats['in']} / Out: {stats['out']})
        </div>
        """

# ----------------------------
# 3. –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ê–ì–ï–ù–¢–ê (Cached)
# ----------------------------
@st.cache_resource(show_spinner=False)
def init_agent_system(
    provider: str,
    model: str, 
    temp: float, 
    max_retries: int
):
    """
    –°–æ–∑–¥–∞–µ—Ç –∏ –∫—ç—à–∏—Ä—É–µ—Ç –≥—Ä–∞—Ñ –∞–≥–µ–Ω—Ç–∞. 
    –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø—Ä–∏–º–∏—Ç–∏–≤–Ω—ã—Ö —Ç–∏–ø–æ–≤ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ —Ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è –∫—ç—à–∞.
    """
    with st.spinner("üîå –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π..."):
        # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑—É –∏–∑ ENV
        config = AgentConfig.from_env()
        
        # 2. –ü—Ä–∏–º–µ–Ω—è–µ–º –æ–≤–µ—Ä—Ä–∞–π–¥—ã –∏–∑ UI
        config.provider = provider
        config.temperature = temp
        config.max_retries = max_retries
        
        if provider == "gemini":
            config.gemini_model = model
        else:
            config.openai_model = model

        # 3. –°–æ–∑–¥–∞–µ–º —Ü–∏–∫–ª –∏ –∞–≥–µ–Ω—Ç–∞
        try:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            agent = loop.run_until_complete(create_agent_graph(config))
            return agent, config, loop
        except Exception as e:
            st.error(f"Critical Error: {e}")
            raise e

# ----------------------------
# 4. SIDEBAR –ò –ù–ê–°–¢–†–û–ô–ö–ò
# ----------------------------
with st.sidebar:
    st.title("üéõÔ∏è Control Panel")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–µ—Ñ–æ–ª—Ç—ã, —á—Ç–æ–±—ã –ø–æ–∫–∞–∑–∞—Ç—å –≤ UI
    env_config = AgentConfig.from_env()
    
    st.subheader("Model Config")
    
    # –í—ã–±–æ—Ä –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ (–µ—Å–ª–∏ –∫–ª—é—á–∏ –µ—Å—Ç—å)
    provider_options = []
    if env_config.gemini_key: provider_options.append("gemini")
    if env_config.openai_key: provider_options.append("openai")
    
    if not provider_options:
        st.error("–ù–µ—Ç API –∫–ª—é—á–µ–π –≤ .env!")
        st.stop()
        
    selected_provider = st.selectbox("Provider", provider_options, index=provider_options.index(env_config.provider) if env_config.provider in provider_options else 0)
    
    # –ú–æ–¥–µ–ª—å (–ø—Ä–æ—Å—Ç–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –ø–æ–ª–µ –¥–ª—è –≥–∏–±–∫–æ—Å—Ç–∏)
    default_model = env_config.gemini_model if selected_provider == "gemini" else env_config.openai_model
    selected_model = st.text_input("Model Name", value=default_model)
    
    st.subheader("Generation")
    ui_temperature = st.slider("Temperature", 0.0, 1.0, env_config.temperature, 0.1)
    ui_max_retries = st.slider("Max Retries", 1, 5, env_config.max_retries)
    
    st.divider()
    
    if st.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é", use_container_width=True):
        st.session_state.session_id = str(uuid.uuid4())
        st.session_state.messages = []
        st.rerun()

    with st.expander("Session Info"):
        st.caption(f"ID: {st.session_state.get('session_id', 'init')}")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è (Singleton)
try:
    agent, config, agent_loop = init_agent_system(
        selected_provider, 
        selected_model, 
        ui_temperature, 
        ui_max_retries
    )
except Exception:
    st.stop()

# ----------------------------
# 5. –£–ü–†–ê–í–õ–ï–ù–ò–ï –°–û–°–¢–û–Ø–ù–ò–ï–ú –ß–ê–¢–ê
# ----------------------------
if "session_id" not in st.session_state:
    st.session_state.session_id = str(uuid.uuid4())

if "messages" not in st.session_state:
    st.session_state.messages = []

# ----------------------------
# 6. –û–¢–†–ò–°–û–í–ö–ê –ò–°–¢–û–†–ò–ò
# ----------------------------
chat_container = st.container()

with chat_container:
    if not st.session_state.messages:
        st.info("üëã –ü—Ä–∏–≤–µ—Ç! –Ø –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ. –ó–∞–¥–∞–π –º–Ω–µ –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –ø–æ–ø—Ä–æ—Å–∏ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∑–∞–¥–∞—á—É.")
        
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])
            # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ç–æ–∫–µ–Ω–æ–≤, –µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å –≤ –∏—Å—Ç–æ—Ä–∏–∏
            if "tokens_html" in msg:
                st.markdown(msg["tokens_html"], unsafe_allow_html=True)

# ----------------------------
# 7. –õ–û–ì–ò–ö–ê –û–ë–†–ê–ë–û–¢–ö–ò (STREAM)
# ----------------------------
async def run_agent_stream(user_input: str, status_placeholder):
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∑–∞–ø—É—Å–∫ –∞–≥–µ–Ω—Ç–∞ —Å –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º UI."""
    
    cfg = {"configurable": {"thread_id": st.session_state.session_id}}
    
    full_text = ""
    token_tracker = TokenTracker()
    response_placeholder = st.empty()
    
    # –¢–∞–π–º–µ—Ä
    start_time = time.time()

    try:
        # –ó–∞–ø—É—Å–∫ —Å—Ç—Ä–∏–º–∞
        async for event in agent.astream(
            {"messages": [HumanMessage(content=user_input)]},
            config=cfg,
            stream_mode="messages"
        ):
            message, meta = event
            node = meta.get("langgraph_node")
            
            # 1. –°—á–∏—Ç–∞–µ–º —Ç–æ–∫–µ–Ω—ã
            token_tracker.update(message)
            
            # 2. –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ –∞–≥–µ–Ω—Ç–∞ (LLM)
            if node == "agent":
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–∑–æ–≤–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
                if hasattr(message, "tool_calls") and message.tool_calls:
                    for tc in message.tool_calls:
                        status_placeholder.write(f"üõ†Ô∏è **–ò—Å–ø–æ–ª—å–∑—É—é –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç:** `{tc['name']}`")
                
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                elif message.content:
                    chunk = message.content
                    if isinstance(chunk, list):
                         # –ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç -> —Ç–µ–∫—Å—Ç
                        chunk = "".join(x["text"] for x in chunk if "text" in x)
                    
                    if chunk:
                        full_text += chunk
                        response_placeholder.markdown(full_text + "‚ñå")

            # 3. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞
            elif node == "tools":
                tool_name = getattr(message, "name", "tool")
                content_preview = str(message.content)[:500]
                if len(str(message.content)) > 500: content_preview += "..."
                
                with status_placeholder.expander(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç: {tool_name}", expanded=False):
                    st.code(content_preview)

        # –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è
        response_placeholder.markdown(full_text)
        duration = time.time() - start_time
        
        return full_text, token_tracker.get_display_html()

    except Exception as e:
        # –õ–æ–≥–∏—Ä—É–µ–º, –Ω–æ –Ω–µ –∫—Ä–∞—à–∏–º –≤–µ—Å—å UI
        st.error(f"–û—à–∏–±–∫–∞ –ø–æ—Ç–æ–∫–∞: {e}")
        return full_text, ""

# ----------------------------
# 8. –û–ë–†–ê–ë–û–¢–ö–ê –í–í–û–î–ê –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø
# ----------------------------
if prompt := st.chat_input("–í–≤–µ–¥–∏—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ..."):
    # 1. –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –≤–æ–ø—Ä–æ—Å
    st.session_state.messages.append({"role": "user", "content": prompt})
    with chat_container:
        with st.chat_message("user"):
            st.markdown(prompt)

    # 2. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
    with chat_container:
        with st.chat_message("assistant"):
            # –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä –¥–ª—è —Å—Ç–∞—Ç—É—Å–∞ (–º—ã—Å–ª–∏, –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã)
            status_box = st.status("üß† –î—É–º–∞—é...", expanded=True)
            
            # –ó–∞–ø—É—Å–∫ –≤–Ω—É—Ç—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ —Å–æ–±—ã—Ç–∏–π
            response_text, token_html = agent_loop.run_until_complete(
                run_agent_stream(prompt, status_box)
            )
            
            # –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞
            status_box.update(label="–ì–æ—Ç–æ–≤–æ", state="complete", expanded=False)
            
            # –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç –ø—É—Å—Ç–æ–π (–æ—à–∏–±–∫–∞), –Ω–µ –¥–æ–±–∞–≤–ª—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
            if response_text:
                st.markdown(token_html, unsafe_allow_html=True)
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": response_text,
                    "tokens_html": token_html
                })